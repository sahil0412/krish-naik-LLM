{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x0000020730B97C40> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000020730C115A0> root_client=<openai.OpenAI object at 0x000002072E2C3A00> root_async_client=<openai.AsyncOpenAI object at 0x0000020730B97C70> model_name='gpt-4o' openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a category of artificial intelligence systems designed to create new content. Unlike traditional AI, which typically focuses on analyzing or predicting based on existing data, generative AI can produce novel outputs that resemble the data it was trained on. This capability is achieved using advanced algorithms, often involving deep learning techniques such as neural networks.\\n\\nSome common applications of generative AI include:\\n\\n1. **Text Generation**: Programs like OpenAI's GPT-4 can produce human-like text, enabling applications in content creation, chatbots, and automated reporting.\\n2. **Image Synthesis**: Tools such as GANs (Generative Adversarial Networks) can create realistic images from scratch, useful in fields like art, design, and even medicine.\\n3. **Music and Audio**: AI can compose music or generate human-like speech, aiding in entertainment and accessibility technologies.\\n4. **Video Creation**: Generative AI can be employed to create realistic video content, which has applications in cinema, advertising, and education.\\n\\nThe underlying technology often involves training models on large datasets, allowing them to learn patterns and structures which they can then mimic or reconstruct in novel ways. This makes generative AI a powerful tool, but also raises ethical considerations around originality, ownership, and the potential for misuse, such as creating deepfakes or generating misleading information.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 270, 'prompt_tokens': 13, 'total_tokens': 283}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5', 'finish_reason': 'stop', 'logprobs': None} id='run-56d93489-bce8-4c4e-ad36-86239bada296-0' usage_metadata={'input_tokens': 13, 'output_tokens': 270, 'total_tokens': 283}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert AI Engineer. Provide me answers based on the questions')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        \n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Certainly! Langsmith is a toolset designed to enhance the development experience when working with language models, particularly those built using the LangChain framework. Here are some of its key features and functionalities:\\n\\n1. **Integrated Development Environment (IDE) Tools**: Langsmith provides an array of tools within an IDE to facilitate the debugging, testing, and evaluation of language models. This helps developers quickly identify and resolve issues within their models.\\n\\n2. **Production Monitoring**: Once a language model is deployed, Langsmith offers robust monitoring capabilities. This ensures that the models are performing as expected in a live environment and helps in maintaining the quality and reliability of the deployed models.\\n\\n3. **Evaluation Capabilities**: Langsmith allows for comprehensive evaluations of language models. This includes automated testing and performance assessments to ensure that models meet the desired benchmarks and performance criteria.\\n\\n4. **Seamless Integration with LangChain**: Since Langsmith is designed to work alongside LangChain, it provides a cohesive development experience for those who are already utilizing LangChain for their language model projects. This integration ensures a smooth workflow from development to deployment.\\n\\nOverall, Langsmith aims to streamline the development lifecycle of language models, making it easier to build, test, debug, and monitor these models effectively.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 254, 'prompt_tokens': 33, 'total_tokens': 287}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5', 'finish_reason': 'stop', 'logprobs': None} id='run-20c4c01d-4e60-45cf-a224-f9c988fe3909-0' usage_metadata={'input_tokens': 33, 'output_tokens': 254, 'total_tokens': 287}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert AI Engineer. Provide me answers based on the questions')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000020730B97C40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000020730C115A0>, root_client=<openai.OpenAI object at 0x000002072E2C3A00>, root_async_client=<openai.AsyncOpenAI object at 0x0000020730B97C70>, model_name='gpt-4o', openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Langsmith is a framework designed to enhance the development and debugging process for applications using large language models (LLMs). It offers several key features that make it particularly useful for AI engineers and developers:\n",
      "\n",
      "1. **Traces**: Langsmith captures detailed traces of interactions between the application and the LLMs. These traces can include inputs, outputs, intermediate steps, and other relevant data. This information is invaluable for understanding how the model is behaving and identifying any issues or unexpected behavior.\n",
      "\n",
      "2. **Debugging**: By providing detailed traces, Langsmith allows developers to pinpoint where things might be going wrong in their applications. This makes it easier to troubleshoot and fix bugs, leading to more robust and reliable applications.\n",
      "\n",
      "3. **Fine-tuning**: Langsmith can be used to collect data that is useful for fine-tuning LLMs. By analyzing the traces, developers can identify patterns and areas where the model's performance could be improved, leading to more effective fine-tuning and better overall model performance.\n",
      "\n",
      "4. **Efficiency**: By streamlining the development and debugging process, Langsmith can help developers work more efficiently. This can lead to faster development cycles and quicker deployment of high-quality applications.\n",
      "\n",
      "Overall, Langsmith is a powerful tool for anyone working with large language models, providing valuable insights and helping to ensure that applications are built and maintained to the highest possible standards.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
